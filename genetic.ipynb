{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./datasets/nuclear.csv\"\n",
    "MODEL = RandomForestClassifier\n",
    "np.random.seed(10564695)\n",
    "TARGET = \"Species\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract calssification target\n",
    "# target = data.loc[:, \"diagnosis\"]\n",
    "# # Convert the target variable to a binary representation (0 or 1)\n",
    "# target = (target == \"M\").astype(int)\n",
    "# # Extract all other columns except 'diagnosis' as predictors\n",
    "# data_predictors = data.loc[:, data.columns != 'diagnosis']\n",
    "# # Create a list of predictor names\n",
    "# predictor_names = data_predictors.columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def preprocess(data):\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == 'object':\n",
    "            if len(data[column].unique()) == 2:\n",
    "                data[column] = pd.Categorical(data[column]).codes\n",
    "            else:\n",
    "                le = LabelEncoder()\n",
    "                data[column] = le.fit_transform(data[column])\n",
    "\n",
    "    return data\n",
    "print(data.head())\n",
    "data = preprocess(data)\n",
    "data_predictors = data.loc[:, data.columns != TARGET]\n",
    "target = data[TARGET]\n",
    "predictor_names = data_predictors.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_predictors, target, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_individuals(population_size, num_features, min_features, max_features):\n",
    "    individuals = np.zeros((population_size, num_features))\n",
    "    for i in range(population_size):\n",
    "        num_ones = np.random.randint(min_features, max_features+1)\n",
    "        ones_indices = np.random.choice(num_features, num_ones, replace=False)\n",
    "        individuals[i, ones_indices] = 1\n",
    "    return individuals\n",
    "\n",
    "multiclass = True if len(data[TARGET].unique()) > 2 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.& 3.: Train model and get precision\n",
    "def train_model(x_train, x_test, y_train, y_test, predictor_names):\n",
    "    x_train = x_train.loc[:, predictor_names]\n",
    "    x_test = x_test.loc[:, predictor_names]\n",
    "    \n",
    "    #Building the random forest model \n",
    "    mdl = MODEL(random_state=1) #Creating the Random Forest Classifier Model\n",
    "    mdl.fit(x_train, y_train)                    #Training the Model with x_train & y_train\n",
    "    y_hat = mdl.predict(x_test)                  #Predicting the x_test \n",
    "    # prec = precision_score(y_test, y_hat)        #Precision: The best value is 1 and the worst value is 0.\n",
    "    if multiclass:\n",
    "        prec = precision_score(y_test, y_hat, average='weighted')\n",
    "    else:\n",
    "        prec = precision_score(y_test, y_hat)\n",
    "\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parents(population,accuracy,elite_percent):\n",
    "    # Get elite of top 2 which doesn't mutate\n",
    "    elite_num = int(round(((elite_percent*population.shape[0]) // 2) * 2))\n",
    "    ind_ac = np.argsort(-accuracy)\n",
    "    top_perc = ind_ac[:elite_num]\n",
    "    elite_population = population[top_perc,:]   # We should keep this elite\n",
    "    \n",
    "    # Normalize accuracy to obtain weights for roulette wheel selection\n",
    "    weight_norm = accuracy / accuracy.sum()     # calculate normalised weight from accuracy\n",
    "    weight_comu = weight_norm.cumsum()          # calc cumulative weight from accuracy\n",
    "   \n",
    "    # Roulette wheel selection   \n",
    "    num_parents_wo_elite = population.shape[0] - elite_num\n",
    "    parents_wo_elite = np.empty([num_parents_wo_elite,population.shape[1]])\n",
    "    for count in range(num_parents_wo_elite):\n",
    "        b = weight_comu[-1]                         # current last element of weight_comu \n",
    "        rand_num = np.random.uniform(0,b)         # random foating-point number btw 0 and current max weight_comu\n",
    "        \n",
    "        indices = np.searchsorted(weight_comu,rand_num) # get indices of the number in weight_comu greater than rand_num\n",
    "        parents_wo_elite[count,:] = population[indices, :]\n",
    "        \n",
    "    parents = np.concatenate((elite_population, parents_wo_elite), axis=0)  # Concatenate elite and parents_wo_elite to get all parents\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_point_crossover(parents,elite_percent,mutation_probability,min_features, max_features):\n",
    "    elite_num = int(round(((elite_percent*population.shape[0]) // 2) * 2))\n",
    "    crossover_population = np.zeros((parents.shape[0],parents.shape[1]))         # first two are elite\n",
    "    crossover_population[0:elite_num,:] = parents[0:elite_num,:]\n",
    "    \n",
    "    for ii in range(int((parents.shape[0]-elite_num)/2)):\n",
    "        n = 2*ii+elite_num                    # gives even number\n",
    "        parents_couple = parents[n:n+2, :]    # comb of parents\n",
    "        b2 = parents.shape[1]                 # num of features\n",
    "        rand_n = np.random.randint(1, b2-1)   # generate rand number from 1 to num_of_features-1\n",
    "        crossover_population[n,:] = np.concatenate([parents_couple[0, :rand_n], parents_couple[1, rand_n:]])\n",
    "        crossover_population[n+1,:] = np.concatenate([parents_couple[1, :rand_n], parents_couple[0, rand_n:]])\n",
    "        \n",
    "    #check if every child has minimum number of features or all true values\n",
    "    for kk in range(crossover_population.shape[0]):\n",
    "        Sum = np.sum(crossover_population[kk,:])\n",
    "        if Sum > max_features:\n",
    "            # if the number of 1s is bigger than max number of features\n",
    "            excess = int(Sum - max_features)\n",
    "            indices = np.where(crossover_population[kk,:] == 1)[0]\n",
    "            position1 = np.random.choice(indices, size=excess, replace=False)       \n",
    "            crossover_population[kk, position1] = 0 # put 0s in random positions\n",
    "        elif Sum < min_features:\n",
    "            # if the number of 1s is smaller than min number of features\n",
    "            missing = int(min_features - Sum)\n",
    "            indices = np.where(crossover_population[kk,:] == 0)[0]\n",
    "            position2 = np.random.choice(indices, size=missing, replace=False) \n",
    "            crossover_population[kk, position2] = 1 # put 1s in random positions\n",
    "\n",
    "    # mutation\n",
    "    child_row = crossover_population.shape[0]\n",
    "    child_col = crossover_population.shape[1]\n",
    "    num_mutations = round(child_row*child_col*mutation_probability)     \n",
    "    for jj in range(num_mutations):\n",
    "        ind_row = np.random.randint(0,child_row) # random number btw 0 and num of rows\n",
    "        ind_col = np.random.randint(0,child_col) # random number btw 0 and num of colmns\n",
    "        if (crossover_population[ind_row,ind_col] == 0 and \n",
    "            np.sum(crossover_population[ind_row,:]) < max_features):\n",
    "            crossover_population[ind_row,ind_col] = 1\n",
    "        elif (crossover_population[ind_row,ind_col] == 1 and \n",
    "              np.sum(crossover_population[ind_row,:]) >= min_features+1):\n",
    "            crossover_population[ind_row,ind_col] = 0 \n",
    "    \n",
    "    return crossover_population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_features = data_predictors.shape[1]\n",
    "min_features = 2            # minimal number of features in a subset of features\n",
    "population_size = 8         # size of population (number of instances)\n",
    "max_iterations = 8          # maximum number of iterations\n",
    "elite_percent = 0.4         # percentage of elite population which doesn't mutate\n",
    "mutation_probability = 0.2  # percentage of total genes that mutate\n",
    "max_features = 4            # maximum number of features in a subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop - gen 0\n",
    "#1&2 generate population\n",
    "population = generate_random_individuals(population_size, num_features, min_features, max_features)   \n",
    "#3&4 train model\n",
    "accuracy = np.zeros(population_size);   \n",
    "predictor_names = data_predictors.columns\n",
    "response_name = target.name                                                 \n",
    "for i in range(population_size):\n",
    "    predictor_names_i = predictor_names[population[i,:]==1]\n",
    "    accuracy_i = train_model(x_train,x_test,y_train,y_test,predictor_names_i)\n",
    "    accuracy[i] = accuracy_i\n",
    "gen = 0\n",
    "best_acc_i = np.zeros(max_iterations)    \n",
    "best_acc_i[gen] = max(accuracy)     # keep best accuracy from 1st gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop - gen > 0\n",
    "while gen < max_iterations-1:\n",
    "    print('Begin iteration num {}/{}'.format(gen+2,max_iterations))\n",
    "    gen += 1\n",
    "    parents = choose_parents(population, accuracy, elite_percent)\n",
    "    children = one_point_crossover(parents,elite_percent,mutation_probability,min_features,max_features)\n",
    "    population = children\n",
    "    for ind in range(population_size):\n",
    "        predictor_names_ind = predictor_names[population[ind,:]==1]\n",
    "        accuracy_ind = train_model(x_train,x_test,y_train,y_test,predictor_names_ind)\n",
    "        accuracy[ind] = accuracy_ind\n",
    "    best_acc_i[gen] = max(accuracy)\n",
    "    \n",
    "ind_max_acc = np.argmax(accuracy)\n",
    "best_features = population[ind_max_acc,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best combination of features: \", predictor_names[best_features==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots - Post-processing\n",
    "best_features_names = predictor_names[best_features==1]\n",
    "plt.plot(range(1, max_iterations + 1), best_acc_i)\n",
    "plt.xlabel('Number of generations')\n",
    "plt.ylabel('Best accuracy')\n",
    "plt.title('Genetic algorithm')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
